{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtD+ZG8bZC4/4kFzwaZcxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Awwab-Khan/decision-tree-classifier-implementation-python/blob/main/Decision_Tree_Implementation_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MsDb-j-xSrMP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"2\"></a>\n",
        "## 2 -  Problem Statement\n",
        "\n",
        "Suppose you are starting a company that grows and sells wild mushrooms.\n",
        "- Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes\n",
        "- You have some existing data that you can use for this task.\n",
        "\n",
        "Can you use the data to help you identify which mushrooms can be sold safely?\n",
        "\n",
        "Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms.\n",
        "\n",
        "\n",
        "\n",
        "<a name=\"3\"></a>\n",
        "## 3 - Dataset\n",
        "\n",
        "You will start by loading the dataset for this task. The dataset you have collected is as follows:\n",
        "\n",
        "|                                                     | Cap Color | Stalk Shape | Solitary | Edible |\n",
        "|:---------------------------------------------------:|:---------:|:-----------:|:--------:|:------:|\n",
        "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
        "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
        "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
        "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
        "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
        "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    Yes   |    0   |\n",
        "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |    Red    |  Enlarging  |    No    |    0   |\n",
        "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
        "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    No    |    1   |\n",
        "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
        "\n",
        "\n",
        "-  You have 10 examples of mushrooms. For each example, you have\n",
        "    - Three features\n",
        "        - Cap Color (`Brown` or `Red`),\n",
        "        - Stalk Shape (`Tapering (as in \\/)` or `Enlarging (as in /\\)`), and\n",
        "        - Solitary (`Yes` or `No`)\n",
        "    - Label\n",
        "        - Edible (`1` indicating yes or `0` indicating poisonous)\n",
        "\n",
        "<a name=\"3.1\"></a>\n",
        "### 3.1 One hot encoded dataset\n",
        "For ease of implementation, we have one-hot encoded the features (turned them into 0 or 1 valued features)\n",
        "\n",
        "|                                                    | Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
        "|:--------------------------------------------------:|:---------:|:--------------------:|:--------:|:------:|\n",
        "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
        "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
        "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
        "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     1    |    0   |\n",
        "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |     0     |           0          |     0    |    0   |\n",
        "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
        "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     0    |    1   |\n",
        "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "\n",
        "\n",
        "Therefore,\n",
        "- `X_train` contains three features for each example\n",
        "    - Brown Color (A value of `1` indicates \"Brown\" cap color and `0` indicates \"Red\" cap color)\n",
        "    - Tapering Shape (A value of `1` indicates \"Tapering Stalk Shape\" and `0` indicates \"Enlarging\" stalk shape)\n",
        "    - Solitary  (A value of `1` indicates \"Yes\" and `0` indicates \"No\")\n",
        "\n",
        "- `y_train` is whether the mushroom is edible\n",
        "    - `y = 1` indicates edible\n",
        "    - `y = 0` indicates poisonous"
      ],
      "metadata": {
        "id": "Vr6Gggb0UQY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
        "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
      ],
      "metadata": {
        "id": "0Ze17AcETlG4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View the variables\n",
        "Let's get more familiar with your dataset.  \n",
        "- A good place to start is to just print out each variable and see what it contains.\n",
        "\n",
        "The code below prints the first few elements of `X_train` and the type of the variable."
      ],
      "metadata": {
        "id": "AXIO4SgqUau9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
        "print(\"Type of X_train:\",type(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99TJ3zEaUYoe",
        "outputId": "9b5779d5-c03e-4cb2-b065-f3789aad8787"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few elements of X_train:\n",
            " [[1 1 1]\n",
            " [1 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 1 1]]\n",
            "Type of X_train: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check the dimensions of your variables\n",
        "\n",
        "Another useful way to get familiar with your data is to view its dimensions.\n",
        "\n",
        "Please print the shape of `X_train` and `y_train` and see how many training examples you have in your dataset."
      ],
      "metadata": {
        "id": "O9pHMDuOUgTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ('The shape of X_train is:', X_train.shape)\n",
        "print ('The shape of y_train is: ', y_train.shape)\n",
        "print ('Number of training examples (m):', len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWN81u3kUeRs",
        "outputId": "50a51455-68fe-49d9-8dfa-d96b77de22a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X_train is: (10, 3)\n",
            "The shape of y_train is:  (10,)\n",
            "Number of training examples (m): 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4\"></a>\n",
        "## 4 - Decision Tree Refresher\n",
        "\n",
        "In this practice lab, you will build a decision tree based on the dataset provided.\n",
        "\n",
        "- Recall that the steps for building a decision tree are as follows:\n",
        "    - Start with all examples at the root node\n",
        "    - Calculate information gain for splitting on all possible features, and pick the one with the highest information gain\n",
        "    - Split dataset according to the selected feature, and create left and right branches of the tree\n",
        "    - Keep repeating splitting process until stopping criteria is met\n",
        "  \n",
        "  \n",
        "- In this lab, you'll implement the following functions, which will let you split a node into left and right branches using the feature with the highest information gain\n",
        "    - Calculate the entropy at a node\n",
        "    - Split the dataset at a node into left and right branches based on a given feature\n",
        "    - Calculate the information gain from splitting on a given feature\n",
        "    - Choose the feature that maximizes information gain\n",
        "    \n",
        "- We'll then use the helper functions you've implemented to build a decision tree by repeating the splitting process until the stopping criteria is met\n",
        "    - For this lab, the stopping criteria we've chosen is setting a maximum depth of 2"
      ],
      "metadata": {
        "id": "GCPyU2uzUj5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Class"
      ],
      "metadata": {
        "id": "6ZK2b6kZU7xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "  def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "      ''' constructor '''\n",
        "\n",
        "      # for decision node\n",
        "      self.feature_index = feature_index\n",
        "      self.threshold = threshold\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.info_gain = info_gain\n",
        "\n",
        "      # for leaf node\n",
        "      self.value = value"
      ],
      "metadata": {
        "id": "0e7h3LVUU7cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DecisionTreeClassifier Class"
      ],
      "metadata": {
        "id": "l7muZAQHV7BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "  def __init__(self, min_samples_split=2, max_depth=2):\n",
        "      ''' constructor '''\n",
        "\n",
        "      # initialize the root of the tree\n",
        "      self.root = None\n",
        "\n",
        "      # stopping conditions\n",
        "      self.min_samples_split = min_samples_split\n",
        "      self.max_depth = max_depth"
      ],
      "metadata": {
        "id": "bh8fD7eaUnqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4.1\"></a>\n",
        "### 4.1  Calculate entropy\n",
        "\n",
        "First, you'll write a helper function called `compute_entropy` that computes the entropy (measure of impurity) at a node.\n",
        "- The function takes in a numpy array (`y`) that indicates whether the examples in that node are edible (`1`) or poisonous(`0`)\n",
        "\n",
        "Complete the `compute_entropy()` function below to:\n",
        "* Compute $p_1$, which is the fraction of examples that are edible (i.e. have value = `1` in `y`)\n",
        "* The entropy is then calculated as\n",
        "\n",
        "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1) \\text{log}_2(1- p_1)$$\n",
        "* Note\n",
        "    * The log is calculated with base $2$\n",
        "    * For implementation purposes, $0\\text{log}_2(0) = 0$. That is, if `p_1 = 0` or `p_1 = 1`, set the entropy to `0`\n",
        "    * Make sure to check that the data at a node is not empty (i.e. `len(y) != 0`). Return `0` if it is\n",
        "    \n",
        "<a name=\"ex01\"></a>\n",
        "### Exercise 1\n",
        "\n",
        "Please complete the `compute_entropy()` function using the previous instructions.\n",
        "    \n",
        "If you get stuck, you can check out the hints presented after the cell below to help you with the implementation."
      ],
      "metadata": {
        "id": "3ehbkCfLUoIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(self, y):\n",
        "    ''' function to compute entropy '''\n",
        "\n",
        "    class_labels = np.unique(y)\n",
        "    entropy = 0\n",
        "    for cls in class_labels:\n",
        "        p_cls = len(y[y == cls]) / len(y)\n",
        "        entropy += -p_cls * np.log2(p_cls)\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "lRzYFKBhUjUc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4.2\"></a>\n",
        "### 4.2  Split dataset\n",
        "\n",
        "Next, you'll write a helper function called `split_dataset` that takes in the data at a node and a feature to split on and splits it into left and right branches. Later in the lab, you'll implement code to calculate how good the split is.\n",
        "\n",
        "- The function takes in the training data, the list of indices of data points at that node, along with the feature to split on.\n",
        "- It splits the data and returns the subset of indices at the left and the right branch.\n",
        "- For example, say we're starting at the root node (so `node_indices = [0,1,2,3,4,5,6,7,8,9]`), and we chose to split on feature `0`, which is whether or not the example has a brown cap.\n",
        "    - The output of the function is then, `left_indices = [0,1,2,3,4,7,9]` (data points with brown cap) and `right_indices = [5,6,8]` (data points without a brown cap)\n",
        "    \n",
        "    \n",
        "|       |                                                    | Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
        "|-------|:--------------------------------------------------:|:---------:|:--------------------:|:--------:|:------:|\n",
        "| 0     | <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
        "| 1     | <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
        "| 2     | <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "| 3     | <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "| 4     | <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
        "| 5     | <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     1    |    0   |\n",
        "| 6     | <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |     0     |           0          |     0    |    0   |\n",
        "| 7     | <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
        "| 8     | <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     0    |    1   |\n",
        "| 9     | <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
        "    "
      ],
      "metadata": {
        "id": "jc3TSe6hWR8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(self, dataset, feature_index, threshold):\n",
        "    ''' function to split the data '''\n",
        "\n",
        "    dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "    dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "    return dataset_left, dataset_right"
      ],
      "metadata": {
        "id": "eoswrRXEWFMz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"4.3\"></a>\n",
        "### 4.3  Calculate information gain\n",
        "\n",
        "Next, you'll write a function called `information_gain` that takes in the training data, the indices at a node and a feature to split on and returns the information gain from the split.\n",
        "\n",
        "<a name=\"ex03\"></a>\n",
        "### Exercise 3\n",
        "\n",
        "Please complete the `compute_information_gain()` function shown below to compute\n",
        "\n",
        "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
        "\n",
        "where\n",
        "- $H(p_1^\\text{node})$ is entropy at the node\n",
        "- $H(p_1^\\text{left})$ and $H(p_1^\\text{right})$ are the entropies at the left and the right branches resulting from the split\n",
        "- $w^{\\text{left}}$ and $w^{\\text{right}}$ are the proportion of examples at the left and right branch, respectively\n",
        "\n",
        "Note:\n",
        "- You can use the `compute_entropy()` function that you implemented above to calculate the entropy\n",
        "- We've provided some starter code that uses the `split_dataset()` function you implemented above to split the dataset\n",
        "\n",
        "If you get stuck, you can check out the hints presented after the cell below to help you with the implementation."
      ],
      "metadata": {
        "id": "F1ufDzzGXK54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(self, parent, l_child, r_child):\n",
        "  weight_l = len(l_child) / len(parent)\n",
        "  weight_r = len(r_child) / len(parent)\n",
        "\n",
        "  info_gain = entropy(self, parent) - (weight_l * entropy(self, l_child) + weight_r * entropy(self, r_child))\n",
        "  return info_gain"
      ],
      "metadata": {
        "id": "tC3r8Y-pXKUR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(self, dataset):\n",
        "  best_split = {}\n",
        "  max_info_gain = -float('inf')\n",
        "\n",
        "  m, n = dataset.shape\n",
        "\n",
        "  for feature_index in range(n):\n",
        "    feature_values = dataset[:, feature_index]\n",
        "    possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "    for threshold in possible_thresholds:\n",
        "      dataset_left, dataset_right = split(self, dataset, feature_index, threshold)\n",
        "      # check if childs are not null\n",
        "      if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "          y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "          # compute information gain\n",
        "          curr_info_gain = information_gain(self, y, left_y, right_y)\n",
        "          # update the best split if needed\n",
        "          if curr_info_gain>max_info_gain:\n",
        "              best_split[\"feature_index\"] = feature_index\n",
        "              best_split[\"threshold\"] = threshold\n",
        "              best_split[\"dataset_left\"] = dataset_left\n",
        "              best_split[\"dataset_right\"] = dataset_right\n",
        "              best_split[\"info_gain\"] = curr_info_gain\n",
        "              max_info_gain = curr_info_gain"
      ],
      "metadata": {
        "id": "EiGkpc5PXjdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}