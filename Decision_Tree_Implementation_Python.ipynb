{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3kPExnQA8B/qQiU7Ndl9c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Awwab-Khan/decision-tree-classifier-implementation-python/blob/main/Decision_Tree_Implementation_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier Implementation in Python using Numpy:"
      ],
      "metadata": {
        "id": "j2gkswJ9YiT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing tools"
      ],
      "metadata": {
        "id": "nLosxf9cLl_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsDb-j-xSrMP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "TOyRWQZsRg1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
        "data = pd.read_csv(\"Iris.csv\", skiprows=1, header=None, names=col_names)\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "0Ze17AcETlG4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "00669fa3-aa33-4b3f-a112-032ab3b704b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width         type\n",
              "1            5.1          3.5           1.4          0.2  Iris-setosa\n",
              "2            4.9          3.0           1.4          0.2  Iris-setosa\n",
              "3            4.7          3.2           1.3          0.2  Iris-setosa\n",
              "4            4.6          3.1           1.5          0.2  Iris-setosa\n",
              "5            5.0          3.6           1.4          0.2  Iris-setosa\n",
              "6            5.4          3.9           1.7          0.4  Iris-setosa\n",
              "7            4.6          3.4           1.4          0.3  Iris-setosa\n",
              "8            5.0          3.4           1.5          0.2  Iris-setosa\n",
              "9            4.4          2.9           1.4          0.2  Iris-setosa\n",
              "10           4.9          3.1           1.5          0.1  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28568141-bbb2-44d0-838f-08b7457d8a13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28568141-bbb2-44d0-838f-08b7457d8a13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28568141-bbb2-44d0-838f-08b7457d8a13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28568141-bbb2-44d0-838f-08b7457d8a13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-04a1972e-35f1-472e-a4f8-16615c1a433b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04a1972e-35f1-472e-a4f8-16615c1a433b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-04a1972e-35f1-472e-a4f8-16615c1a433b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.828066127977863,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4335943113621737,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7644204199522626,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7631607417008411,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Iris-setosa\",\n          \"Iris-versicolor\",\n          \"Iris-virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Encoding target variable"
      ],
      "metadata": {
        "id": "Pm8YWi6zRi4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lc = LabelEncoder()\n",
        "data['type'] = lc.fit_transform(data['type'])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "byUcpCnEzQwP",
        "outputId": "5bb39b5e-926d-4394-c027-347d522bb4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width  type\n",
              "1           5.1          3.5           1.4          0.2     0\n",
              "2           4.9          3.0           1.4          0.2     0\n",
              "3           4.7          3.2           1.3          0.2     0\n",
              "4           4.6          3.1           1.5          0.2     0\n",
              "5           5.0          3.6           1.4          0.2     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4adbd0d-9a67-48a2-af01-18965fd88748\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4adbd0d-9a67-48a2-af01-18965fd88748')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4adbd0d-9a67-48a2-af01-18965fd88748 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4adbd0d-9a67-48a2-af01-18965fd88748');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5532356-9928-4d47-b307-8e8db9a85fac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5532356-9928-4d47-b307-8e8db9a85fac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5532356-9928-4d47-b307-8e8db9a85fac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.828066127977863,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4335943113621737,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7644204199522626,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7631607417008411,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
      ],
      "metadata": {
        "id": "RUU2ZpPe5hGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the variables\n",
        "Let's get more familiar with the dataset.  \n",
        "- A good place to start is to just print out each variable and see what it contains.\n",
        "\n",
        "The code below prints the first few elements of `X_train` and the type of the variable."
      ],
      "metadata": {
        "id": "AXIO4SgqUau9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
        "print(\"Type of X_train:\",type(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99TJ3zEaUYoe",
        "outputId": "fb5e85c4-0fa4-478e-b90d-92f9b3e3d463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few elements of X_train:\n",
            " [[5.7 2.6 3.5 1. ]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.7 3.  5.2 2.3]]\n",
            "Type of X_train: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the dimension of variables\n",
        "\n",
        "Another useful way to get familiar with your data is to view its dimensions.\n",
        "\n",
        "Please print the shape of `X_train` and `y_train` and see how many training examples you have in your dataset."
      ],
      "metadata": {
        "id": "O9pHMDuOUgTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ('The shape of X_train is:', X_train.shape)\n",
        "print ('The shape of y_train is: ', Y_train.shape)\n",
        "print ('Number of training examples (m):', len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWN81u3kUeRs",
        "outputId": "4887887b-74d5-400a-822e-9cf333c192ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X_train is: (120, 4)\n",
            "The shape of y_train is:  (120, 1)\n",
            "Number of training examples (m): 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Refresher\n",
        "Decision trees are a fundamental machine learning model used for both classification and regression tasks. They work by recursively partitioning the feature space into regions, with the goal of making predictions based on the majority class (for classification) or mean value (for regression) within each region. Here's a breakdown of key concepts:\n",
        "\n",
        "1. **Splitting Criterion**: At each node of the tree, a decision is made to split the data based on a chosen feature and threshold value. The objective is to maximize the information gain or minimize impurity in the resulting subsets.\n",
        "\n",
        "2. **Information Gain**: Measures the reduction in entropy (for classification) or variance (for regression) achieved by splitting the data at a particular node. Higher information gain indicates a more effective split.\n",
        "\n",
        "3. **Leaf Nodes**: Terminal nodes of the decision tree that represent the final prediction for a given subset of the data. For classification, the majority class in the leaf node is used as the prediction.\n"
      ],
      "metadata": {
        "id": "wchhfMGvMxTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DecisionTreeClassifier Implementation Description\n",
        "Now, let's dive into the description of your `DecisionTreeClassifier` implementation, referencing specific function names and components from your provided code.\n",
        "\n",
        "### Components:\n",
        "1. **Node Class** (`Node`):\n",
        "   - Represents a node in the decision tree.\n",
        "   - Attributes:\n",
        "     - `feature_index`: Index of the feature used for splitting at this node.\n",
        "     - `threshold`: Threshold value for the feature used in the splitting decision.\n",
        "     - `left`: Pointer to the left child node.\n",
        "     - `right`: Pointer to the right child node.\n",
        "     - `info_gain`: Information gain achieved by the split at this node (for decision nodes).\n",
        "     - `value`: Predicted value (class label or regression target) for leaf nodes.\n",
        "\n"
      ],
      "metadata": {
        "id": "DsXPV1PWVIzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Set, Dict, Optional, Any"
      ],
      "metadata": {
        "id": "DA3pDOc1V0GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    \"\"\"A class representing a node in a decision tree.\n",
        "\n",
        "    Attributes:\n",
        "        feature_index (Optional[int]): The index of the feature used for splitting at this node.\n",
        "        threshold (Optional[float]): The threshold value for the feature used in the splitting decision.\n",
        "        left (Optional[Node]): The left child node.\n",
        "        right (Optional[Node]): The right child node.\n",
        "        info_gain (Optional[float]): The information gain achieved by the split at this node (for decision nodes).\n",
        "        value (Optional[int]): The predicted value for leaf nodes (e.g., class label for classification).\n",
        "\n",
        "    Note:\n",
        "        - For decision nodes (non-leaf), `feature_index` and `threshold` determine the splitting condition.\n",
        "        - `left` and `right` are pointers to the left and right child nodes resulting from the split.\n",
        "        - `info_gain` represents the information gain achieved by the split.\n",
        "        - For leaf nodes, `value` holds the predicted value (e.g., class label) based on majority voting.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        feature_index: Optional[int] = None,\n",
        "        threshold: Optional[float] = None,\n",
        "        left: Optional['Node'] = None,\n",
        "        right: Optional['Node'] = None,\n",
        "        info_gain: Optional[float] = None,\n",
        "        value: Optional[int] = None,\n",
        "    ):\n",
        "        \"\"\"Initialize a Node object with specified attributes.\n",
        "\n",
        "        Args:\n",
        "            feature_index (Optional[int]): The index of the feature used for splitting.\n",
        "            threshold (Optional[float]): The threshold value for the feature used in splitting.\n",
        "            left (Optional[Node]): The left child node.\n",
        "            right (Optional[Node]): The right child node.\n",
        "            info_gain (Optional[float]): The information gain achieved by the split.\n",
        "            value (Optional[int]): The predicted value for leaf nodes.\n",
        "\n",
        "        \"\"\"\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value\n"
      ],
      "metadata": {
        "id": "0e7h3LVUU7cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Decision Tree Classifier Class** (`DecisionTreeClassifier`):\n",
        "   - Implements a decision tree classifier using a binary tree structure.\n",
        "\n",
        "### Methods:\n",
        "1. **`fit(X, Y)`**:\n",
        "   - Trains the decision tree classifier on the input training data (`X` features, `Y` labels).\n",
        "   - Constructs the tree using the provided training dataset by recursively calling `build_tree`.\n",
        "\n",
        "I apologize for the oversight. Let's correct the description of the `build_tree` method to accurately reflect that your implementation is iterative using a stack and while loop instead of recursive. Here's the revised description:\n",
        "\n",
        "2. **`build_tree(dataset)`**\n",
        "- Iterative function to build the decision tree using a stack-based approach.\n",
        "- Inputs:\n",
        "  - `dataset`: Training dataset represented as a NumPy array with features and labels.\n",
        "\n",
        "- Steps:\n",
        "  1. Initialize the root node of the tree.\n",
        "  2. Use a stack to manage nodes and their corresponding datasets during tree construction.\n",
        "  3. Push the initial state onto the stack with the entire dataset and the root node.\n",
        "  4. While the stack is not empty:\n",
        "    - Pop a node and its associated dataset from the stack.\n",
        "    - Extract features (`X`) and labels (`Y`) from the dataset.\n",
        "    - Check stopping conditions (minimum samples or maximum depth):\n",
        "      - If stopping conditions are met, compute and assign the predicted value (`value`) for the leaf node based on `Y`.\n",
        "      - Otherwise, proceed with tree expansion:\n",
        "        - Find the best split (`get_best_split`) based on information gain using the current dataset.\n",
        "        - If a valid split is found (positive information gain), create decision nodes (`Node`) for the current feature and threshold.\n",
        "        - Partition the dataset into left and right subsets based on the best split.\n",
        "        - Push the left and right child nodes along with their respective datasets onto the stack for further processing.\n",
        "\n",
        "3. **`get_best_split(dataset, num_samples, num_features)`**:\n",
        "   - Finds the best feature and threshold to split the dataset based on maximum information gain.\n",
        "   - Loops through each feature and possible thresholds to calculate information gain for potential splits.\n",
        "   - Returns a dictionary containing the best split information.\n",
        "\n",
        "4. **`split(dataset, feature_index, threshold)`**:\n",
        "   - Splits the dataset into left and right subsets based on a given feature and threshold.\n",
        "\n",
        "5. **`information_gain(parent, l_child, r_child, mode=\"gini\")`**:\n",
        "   - Computes information gain based on the impurity measure (Gini index or entropy).\n",
        "\n",
        "6. **`calculate_leaf_value(Y)`**:\n",
        "   - Determines the predicted value for a leaf node based on the majority class (classification) or mean value (regression) of the labels `Y`.\n",
        "\n",
        "7. **`print_tree(tree=None, indent=\" \")`**:\n",
        "   - Recursively prints the structure of the decision tree for visualization purposes.\n",
        "\n",
        "8. **`predict(X)`**:\n",
        "   - Makes predictions for input data `X` using the trained decision tree.\n",
        "   - Calls `make_prediction` for each data point in `X`.\n",
        "\n",
        "9. **`make_prediction(x, tree)`**:\n",
        "   - Recursively traverses the decision tree to predict the label for a single data point `x`.\n",
        "   - Handles cases where the tree traversal reaches leaf nodes (`tree.value` is not `None`) or decision nodes (based on feature and threshold).\n"
      ],
      "metadata": {
        "id": "l7muZAQHV7BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mathematical Equations\n",
        "\n",
        "#### Entropy Calculation ($H(S)$)\n",
        "The entropy is a measure of impurity or randomness in a dataset. For a classification problem with classes $(C_1, C_2, \\ldots, C_k)$, the entropy $H(S)$ of a set $(S)$ with class labels $(y)$ is calculated as:\n",
        "\n",
        "$$ H(S) = -\\sum_{i=1}^k p_i \\log_2(p_i) $$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $p_i$ is the proportion of examples in class $C_i$ in the dataset $(S)$.\n",
        "\n",
        "- $log_2$ denotes the logarithm base 2.\n",
        "\n",
        "In code:\n",
        "```python\n",
        "def entropy(y):\n",
        "    class_labels = np.unique(y)\n",
        "    entropy = 0\n",
        "    for cls in class_labels:\n",
        "        p_cls = len(y[y == cls]) / len(y)\n",
        "        entropy += -p_cls * np.log2(p_cls)\n",
        "    return entropy\n",
        "```\n",
        "\n",
        "#### Gini Index Calculation ($Gini(S)$)\n",
        "The Gini index is another measure of impurity often used in decision trees. It measures the probability that a randomly chosen element from the set would be incorrectly classified if it was randomly labeled according to the distribution of labels in the set.\n",
        "\n",
        "$$ {Gini}(S) = 1 - \\sum_{i=1}^k p_i^2 $$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $p_i$ is the proportion of examples in class $C_i$ in the dataset $S$.\n",
        "\n",
        "In code:\n",
        "```python\n",
        "def gini_index(y):\n",
        "    class_labels = np.unique(y)\n",
        "    gini = 0\n",
        "    for cls in class_labels:\n",
        "        p_cls = len(y[y == cls]) / len(y)\n",
        "        gini += p_cls**2\n",
        "    return 1 - gini\n",
        "```\n",
        "\n",
        "#### Information Gain Calculation  ($IG(parent, l\\_child, r\\_child)$)\n",
        "Information gain measures the reduction in entropy (or increase in purity) achieved by splitting a dataset $S$ into subsets $S_{left}$ and $S_{right}$\n",
        "\n",
        "$$ \\text{Information Gain} = \\text{Impurity}(S) - \\left( \\frac{|S_{{left}}|}{|S|} \\times \\text{Impurity}(S_{{left}}) + \\frac{|S_{{right}}|}{|S|} \\times \\text{Impurity}(S_{{right}}) \\right) $$\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\text{Impurity}(S)$ is the impurity measure (entropy or Gini index) of the dataset $S$.\n",
        "\n",
        "- $|S|$ is the total number of examples in dataset \\(S\\).\n",
        "\n",
        "- $|S_{{left}}|$ and $|S_{{right}}|$ are the number of examples in the left and right subsets after splitting.\n",
        "\n",
        "In code:\n",
        "```python\n",
        "def information_gain(parent, l_child, r_child, mode=\"gini\"):\n",
        "    weight_l = len(l_child) / len(parent)\n",
        "    weight_r = len(r_child) / len(parent)\n",
        "    \n",
        "    if mode == \"gini\":\n",
        "        impurity_parent = gini_index(parent)\n",
        "        impurity_l = gini_index(l_child)\n",
        "        impurity_r = gini_index(r_child)\n",
        "    else:  # mode == \"entropy\"\n",
        "        impurity_parent = entropy(parent)\n",
        "        impurity_l = entropy(l_child)\n",
        "        impurity_r = entropy(r_child)\n",
        "    \n",
        "    gain = impurity_parent - (weight_l * impurity_l + weight_r * impurity_r)\n",
        "    return gain\n",
        "```\n",
        "\n",
        "#### Accuracy Calculation ($\\text{accuracy}(Y_{\\text{true}}, Y_{\\text{pred}})$)\n",
        "The accuracy score measures the proportion of correctly predicted labels compared to the true labels in a dataset.\n",
        "\n",
        "$$ \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} $$\n",
        "\n",
        "In code (using `sklearn.metrics.accuracy_score`):\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Example usage\n",
        "Y_true = [true_label1, true_label2, ...]\n",
        "Y_pred = [predicted_label1, predicted_label2, ...]\n",
        "accuracy = accuracy_score(Y_true, Y_pred)\n",
        "```"
      ],
      "metadata": {
        "id": "GvIbrp2tmZqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation"
      ],
      "metadata": {
        "id": "wgY4AWL8mmeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "    \"\"\"A decision tree classifier implementation using an iterative build approach.\n",
        "\n",
        "    Attributes:\n",
        "        root (Optional[Node]): The root node of the decision tree.\n",
        "        min_samples_split (int): The minimum number of samples required to split a node.\n",
        "        max_depth (int): The maximum depth of the decision tree.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, min_samples_split: int = 2, max_depth: int = 2):\n",
        "        \"\"\"Initialize the DecisionTreeClassifier.\n",
        "\n",
        "        Args:\n",
        "            min_samples_split (int): The minimum number of samples required to split a node.\n",
        "            max_depth (int): The maximum depth of the decision tree.\n",
        "\n",
        "        \"\"\"\n",
        "        self.root: Optional[Node] = None\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def build_tree(self, dataset: np.ndarray) -> Node:\n",
        "        \"\"\"Iteratively build the decision tree.\n",
        "\n",
        "        Args:\n",
        "            dataset (np.ndarray): The training dataset (features + labels).\n",
        "\n",
        "        Returns:\n",
        "            Node: The root node of the constructed decision tree.\n",
        "\n",
        "        \"\"\"\n",
        "        self.root = Node()\n",
        "        stack: List[Tuple[np.ndarray, Node, int]] = [(dataset, self.root, 0)]\n",
        "\n",
        "        while stack:\n",
        "            data, node, depth = stack.pop()\n",
        "            X, Y = data[:, :-1], data[:, -1]\n",
        "            num_samples, num_features = np.shape(X)\n",
        "\n",
        "            if num_samples < self.min_samples_split or depth > self.max_depth:\n",
        "                node.value = self.calculate_leaf_value(Y)\n",
        "            else:\n",
        "                best_split = self.get_best_split(data, num_samples, num_features)\n",
        "\n",
        "                if best_split[\"info_gain\"] > 0:\n",
        "                    node.feature_index = best_split[\"feature_index\"]\n",
        "                    node.threshold = best_split[\"threshold\"]\n",
        "                    node.info_gain = best_split[\"info_gain\"]\n",
        "\n",
        "                    left_subtree = Node()\n",
        "                    node.left = left_subtree\n",
        "                    stack.append((best_split[\"dataset_left\"], left_subtree, depth + 1))\n",
        "\n",
        "                    right_subtree = Node()\n",
        "                    node.right = right_subtree\n",
        "                    stack.append((best_split[\"dataset_right\"], right_subtree, depth + 1))\n",
        "                else:\n",
        "                    node.value = self.calculate_leaf_value(Y)\n",
        "\n",
        "        return self.root\n",
        "\n",
        "    def get_best_split(self, dataset: np.ndarray, num_samples: int, num_features: int) -> dict:\n",
        "        \"\"\"Find the best split based on information gain.\n",
        "\n",
        "        Args:\n",
        "            dataset (np.ndarray): The dataset to find the best split.\n",
        "            num_samples (int): The number of samples in the dataset.\n",
        "            num_features (int): The number of features in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the best split information.\n",
        "\n",
        "        \"\"\"\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in possible_thresholds:\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "\n",
        "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "\n",
        "                    if curr_info_gain > max_info_gain:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"info_gain\"] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset: np.ndarray, feature_index: int, threshold: float) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Split the dataset based on a given feature and threshold.\n",
        "\n",
        "        Args:\n",
        "            dataset (np.ndarray): The dataset to split.\n",
        "            feature_index (int): The index of the feature to use for splitting.\n",
        "            threshold (float): The threshold value for splitting the feature.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.ndarray, np.ndarray]: A tuple containing the left and right split datasets.\n",
        "\n",
        "        \"\"\"\n",
        "        dataset_left = dataset[dataset[:, feature_index] <= threshold]\n",
        "        dataset_right = dataset[dataset[:, feature_index] > threshold]\n",
        "        return dataset_left, dataset_right\n",
        "\n",
        "    def information_gain(self, parent: np.ndarray, l_child: np.ndarray, r_child: np.ndarray, mode: str = \"entropy\") -> float:\n",
        "        \"\"\"Compute the information gain based on Gini impurity or entropy.\n",
        "\n",
        "        Args:\n",
        "            parent (np.ndarray): The labels of the parent node.\n",
        "            l_child (np.ndarray): The labels of the left child node.\n",
        "            r_child (np.ndarray): The labels of the right child node.\n",
        "            mode (str): The impurity measure to use ('entropy' or 'gini').\n",
        "\n",
        "        Returns:\n",
        "            float: The computed information gain.\n",
        "\n",
        "        \"\"\"\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "\n",
        "        if mode == \"gini\":\n",
        "            gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
        "        else:\n",
        "            gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
        "\n",
        "        return gain\n",
        "\n",
        "    def entropy(self, y: np.ndarray) -> float:\n",
        "        \"\"\"Compute the entropy for a given set of labels.\n",
        "\n",
        "        Args:\n",
        "            y (np.ndarray): The array of labels.\n",
        "\n",
        "        Returns:\n",
        "            float: The computed entropy.\n",
        "\n",
        "        \"\"\"\n",
        "        class_labels, class_counts = np.unique(y, return_counts=True)\n",
        "        entropy = -np.sum((class_counts / len(y)) * np.log2(class_counts / len(y)))\n",
        "        return entropy\n",
        "\n",
        "    def gini_index(self, y: np.ndarray) -> float:\n",
        "        \"\"\"Compute the Gini index for a given set of labels.\n",
        "\n",
        "        Args:\n",
        "            y (np.ndarray): The array of labels.\n",
        "\n",
        "        Returns:\n",
        "            float: The computed Gini index.\n",
        "\n",
        "        \"\"\"\n",
        "        class_labels, class_counts = np.unique(y, return_counts=True)\n",
        "        gini = 1.0 - np.sum((class_counts / len(y)) ** 2)\n",
        "        return gini\n",
        "\n",
        "    def calculate_leaf_value(self, Y: np.ndarray) -> int:\n",
        "        \"\"\"Compute the leaf node value (predicted class label).\n",
        "\n",
        "        Args:\n",
        "            Y (np.ndarray): The array of labels.\n",
        "\n",
        "        Returns:\n",
        "            int: The predicted class label (majority class).\n",
        "\n",
        "        \"\"\"\n",
        "        return np.argmax(np.bincount(Y.astype(int)))\n",
        "\n",
        "    def fit(self, X: np.ndarray, Y: np.ndarray) -> None:\n",
        "        \"\"\"Train the decision tree classifier.\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): The feature matrix.\n",
        "            Y (np.ndarray): The target labels.\n",
        "\n",
        "        \"\"\"\n",
        "        dataset = np.concatenate((X, Y.reshape(-1, 1)), axis=1)\n",
        "        self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> List[int]:\n",
        "        \"\"\"Predict the class labels for new input data.\n",
        "\n",
        "        Args:\n",
        "            X (np.ndarray): The input feature matrix.\n",
        "\n",
        "        Returns:\n",
        "            List[int]: The predicted class labels.\n",
        "\n",
        "        \"\"\"\n",
        "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return predictions\n",
        "\n",
        "    def make_prediction(self, x: np.ndarray, tree: Node) -> int:\n",
        "        \"\"\"Make a prediction for a single data point using the decision tree.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The input data point (features).\n",
        "            tree (Node): The root node of the decision tree.\n",
        "\n",
        "        Returns:\n",
        "            int: The predicted class label.\n",
        "\n",
        "        \"\"\"\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "\n",
        "        feature_val = x[tree.feature_index]\n",
        "\n",
        "        if feature_val <= tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)"
      ],
      "metadata": {
        "id": "eotVqOl4sc5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the model"
      ],
      "metadata": {
        "id": "IWNkVPsYr6zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "# classifier.print_tree()"
      ],
      "metadata": {
        "id": "KBjINcsHr9Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ],
      "metadata": {
        "id": "6fB-RYEPVlBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(f\"Accuracy: {round(accuracy_score(Y_test, Y_pred), 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbqdM3hjtHab",
        "outputId": "272cde4c-20d0-4d4b-be8a-7f04befb9697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Conclusion\n",
        "Understanding the mathematical foundations behind decision trees, including entropy, Gini index, information gain, and accuracy, is essential for building and interpreting machine learning models effectively. By using this approach into my `DecisionTreeClassifier` implementation, I was able to achieve an impressive accuracy of 93% on Iris dataset."
      ],
      "metadata": {
        "id": "suVWfuWEXl2j"
      }
    }
  ]
}